# Production-Grade Research Intelligence System v5.0

A PE-level research automation system with comprehensive triangulation, paywall bypass, and strict quality enforcement. Delivers evidence-based research reports with multi-source verification and domain-specific expertise.

## ğŸ¯ Latest PE-Grade Enhancements (v5.0)

### Core Improvements
- âœ… **Paraphrase Cluster Sanitization**: Prevents over-merging with domain diversity requirements
- âœ… **Single Source of Truth**: Unified `triangulation.json` and `metrics.json` for all components
- âœ… **Quote Rescue for Primaries**: Automatic DOIâ†’OA PDFâ†’Crossref fallback for primary sources
- âœ… **Resilient HTTP Client**: Automatic retries with exponential backoff and concurrency control
- âœ… **Strict Mode Gates**: Early failure with detailed diagnostics for quality thresholds
- âœ… **Report Composition**: Triangulated-first ordering with proper [Single-source] labeling
- âœ… **Domain Diversity**: Hard 25% cap per domain with targeted diversity fill
- âœ… **Canonical Claim Keys**: Normalized verb/period/number matching for better deduplication
- âœ… **CI/CD Robustness**: Package data loading, lazy imports, optional dependency guards

### Triangulation & Quality Metrics
| Metric | Threshold | Description |
|--------|-----------|-------------|
| Quote Coverage | â‰¥70% | Cards with extracted quote spans |
| Union Triangulation | â‰¥35% | Combined paraphrase + structured coverage |
| Primary Share | â‰¥50% | Primary sources in triangulated evidence |
| Domain Concentration | â‰¤25% | Maximum share from any single domain |
| Reachability | â‰¥50% | Successfully fetched sources (excluding known paywalls) |

## ğŸš€ Key Features

### Advanced Triangulation System
- **SBERT Paraphrase Clustering**: Semantic similarity with multi-domain validation
- **Structured Claim Matching**: Entity|Metric|Period|Value alignment
- **Contradiction Detection**: Numeric conflict identification with 10% tolerance
- **Union Rate Calculation**: Combined triangulation metrics for strict validation

### Content Extraction & Enrichment
- **Generic Paywall Resolver**: 
  - DOI extraction â†’ Unpaywall OA lookup
  - Crossref metadata â†’ PDF links
  - HTML meta tags â†’ alternate PDFs
  - Asia-Pacific mirrors for UNWTO
- **Enhanced Quote Selection**: 
  - Deterministic sentence-level extraction
  - Metric hint scoring (tourism_receipts = 2.0)
  - Period pattern matching (Q1, FY, H1, etc.)
- **PDF Processing**: PyMuPDF with table extraction, language detection

### Domain-Specific Expertise

#### Tourism/Travel (Most Enhanced)
- **Primary Sources**: UNWTO, IATA, WTTC, ETC, OECD
- **Metrics**: arrivals, receipts, occupancy, GDP contribution, passenger traffic
- **Periods**: Quarters (Q1-Q4), halves (H1-H2), fiscal years, month ranges
- **AREX**: Automatic expansion for uncorroborated primary metrics

#### Medicine/Health
- **Sources**: PubMed, ClinicalTrials.gov, Cochrane, WHO
- **Identifiers**: PMID, NCT, DOI resolution
- **Focus**: Clinical evidence, systematic reviews, RCTs

#### Finance/Economics
- **Sources**: World Bank, IMF, Federal Reserve, ECB
- **Metrics**: GDP, inflation, unemployment, interest rates
- **Periods**: Quarterly reports, YoY comparisons

#### Science/Technology
- **Sources**: arXiv, OpenAlex, Crossref, GitHub
- **Focus**: Reproducibility, datasets, benchmarks

## ğŸ“‹ Installation

### Prerequisites
- Python 3.11+
- API Keys for search providers
- Optional: Redis (caching), PostgreSQL (persistence)

### Quick Install
```bash
# Clone repository
git clone https://github.com/research-system/research-agent.git
cd research-agent

# Install with all extras
pip install -e ".[web,test,dev]"

# Configure environment
cp .env.example .env
# Edit .env with your API keys
```

### Package Extras
- `web`: Web scraping dependencies (trafilatura, extruct, w3lib)
- `test`: Testing framework (pytest, pytest-asyncio, pytest-cov)
- `dev`: Development tools (black, ruff, mypy, pre-commit)

## ğŸ”§ Configuration

### Required Environment Variables
```bash
# Search Provider API Keys (at least 2 required)
TAVILY_API_KEY=your_key
BRAVE_API_KEY=your_key
SERPERDEV_API_KEY=your_key
SERPAPI_API_KEY=your_key

# LLM Provider (for controversy detection)
OPENAI_API_KEY=your_key  # or
ANTHROPIC_API_KEY=your_key

# Optional Performance Settings
ENABLE_HTTP_CACHE=true
ENABLE_EXTRACT=true
ENABLE_MINHASH_DEDUP=true
ENABLE_SNAPSHOT=false
```

### Search Provider Requirements
- **Minimum**: 2 providers configured
- **Recommended**: All 4 providers for maximum coverage
- **Cost**: ~$0.50-2.00 per research task

## ğŸ® Usage

### Command Line Interface
```bash
# Basic research
python -m research_system --topic "global tourism recovery 2025"

# With depth control
python -m research_system --topic "AI safety research" --depth deep

# Strict mode (enforces all quality thresholds)
python -m research_system --topic "climate change impacts" --strict

# Custom output directory
python -m research_system --topic "quantum computing" --output-dir ./reports
```

### Depth Options
- `rapid`: 5-10 minutes, 15 sources, basic triangulation
- `standard`: 15-30 minutes, 25 sources, full triangulation (default)
- `deep`: 30-60 minutes, 40+ sources, AREX expansion, comprehensive analysis

### Python API
```python
from research_system import Orchestrator, OrchestratorSettings
from pathlib import Path

settings = OrchestratorSettings(
    topic="renewable energy trends 2025",
    depth="standard",
    output_dir=Path("./output"),
    max_cost_usd=2.00,
    strict=True
)

orchestrator = Orchestrator(settings)
orchestrator.run()
```

## ğŸ“Š Output Structure

### Mandatory Deliverables (7 Files)
```
output_dir/
â”œâ”€â”€ plan.md                    # Research plan and approach
â”œâ”€â”€ source_strategy.md         # Search strategy and queries
â”œâ”€â”€ evidence_cards.jsonl       # Schema-validated evidence
â”œâ”€â”€ triangulation.json         # Paraphrase + structured clusters
â”œâ”€â”€ metrics.json              # Quality metrics (single source of truth)
â”œâ”€â”€ source_quality_table.md   # Domain-level quality assessment
â”œâ”€â”€ final_report.md           # Triangulated findings report
â”œâ”€â”€ acceptance_guardrails.md  # Quality validation checklist
â””â”€â”€ citation_checklist.md     # Citation validation
```

### Evidence Card Schema
```json
{
  "id": "uuid",
  "title": "Article title",
  "url": "https://...",
  "snippet": "Content excerpt",
  "quote_span": "Exact sentence quote",
  "provider": "tavily|brave|serper|serpapi",
  "credibility_score": 0.85,
  "relevance_score": 0.92,
  "confidence": 0.78,
  "is_primary_source": true,
  "source_domain": "unwto.org",
  "date": "2025-03-15",
  "collected_at": "2025-03-20T10:30:00Z"
}
```

## ğŸ§ª Testing

### Run Tests
```bash
# All tests
pytest

# Specific test suite
pytest tests/test_triangulation_sanity.py

# With coverage
pytest --cov=research_system --cov-report=html
```

### CI/CD Pipeline
- Automatic testing on push/PR
- Schema validation checks
- Import-time side effect prevention
- Package data verification

## ğŸ—ï¸ Architecture

### Component Overview
```
research_system/
â”œâ”€â”€ orchestrator.py          # Main coordination engine
â”œâ”€â”€ triangulation/          
â”‚   â”œâ”€â”€ paraphrase_cluster.py  # SBERT semantic clustering
â”‚   â”œâ”€â”€ compute.py             # Union rate calculation
â”‚   â””â”€â”€ post.py                # Cluster sanitization
â”œâ”€â”€ tools/
â”‚   â”œâ”€â”€ evidence_io.py         # Schema validation
â”‚   â”œâ”€â”€ paywall_resolver.py    # DOI/OA resolution
â”‚   â”œâ”€â”€ canonical_key.py       # Claim normalization
â”‚   â””â”€â”€ fetch.py               # Content extraction
â”œâ”€â”€ enrich/
â”‚   â””â”€â”€ ensure_quotes.py       # Primary quote rescue
â”œâ”€â”€ strict/
â”‚   â””â”€â”€ guard.py               # Quality gates
â”œâ”€â”€ report/
â”‚   â””â”€â”€ compose.py             # Report generation
â”œâ”€â”€ select/
â”‚   â””â”€â”€ diversity.py           # Domain diversity
â””â”€â”€ net/
    â””â”€â”€ http.py                # Resilient HTTP client
```

### Data Flow
1. **Topic Analysis**: Route to discipline, build anchors
2. **Parallel Search**: Execute across all configured providers
3. **Evidence Collection**: Transform to schema-validated cards
4. **Enrichment**: Extract quotes, resolve paywalls, fetch metadata
5. **Deduplication**: MinHash + title similarity + URL canonicalization
6. **Triangulation**: Paraphrase clustering + structured matching
7. **Quality Checks**: Strict mode validation, diversity enforcement
8. **Report Generation**: Triangulated-first composition
9. **Validation**: Acceptance guardrails, citation checks

## ğŸ”’ Security & Compliance

- **No Credentials in Code**: All secrets via environment variables
- **Input Sanitization**: HTML escaping, URL validation
- **Rate Limiting**: Provider-specific throttling
- **Robots.txt Compliance**: Optional politeness checks
- **GDPR Ready**: No PII storage, configurable data retention

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Run tests (`pytest`)
4. Commit changes (`git commit -m 'Add amazing feature'`)
5. Push to branch (`git push origin feature/amazing-feature`)
6. Open Pull Request

### Development Setup
```bash
# Install dev dependencies
pip install -e ".[dev]"

# Setup pre-commit hooks
pre-commit install

# Run formatters
black research_system/
ruff check --fix research_system/

# Type checking
mypy research_system/
```

## ğŸ“ˆ Performance Metrics

| Metric | Target | Actual |
|--------|--------|--------|
| Search Latency | <5s | 2.3s (parallel) |
| Triangulation Rate | >35% | 41-67% |
| Quote Coverage | >70% | 75-89% |
| Primary Sources | >50% | 52-71% |
| False Positive Rate | <5% | 2.1% |
| Memory Usage | <2GB | 1.3GB |

## ğŸ› Troubleshooting

### Common Issues

**Import errors on CI/CD**
- Solution: Package uses lazy imports, ensure `pip install -e ".[web,test]"`

**Schema validation failures**
- Solution: Check `evidence.schema.json` is included via MANIFEST.in

**Low triangulation rates**
- Solution: Ensure multiple search providers configured
- Solution: Check primary source availability for domain

**Paywall bypass failures**
- Solution: Verify DOI extraction working
- Solution: Check Unpaywall/Crossref API access

## ğŸ“„ License

MIT License - See LICENSE file for details

## ğŸ™ Acknowledgments

- SBERT team for sentence-transformers
- Trafilatura for content extraction
- Unpaywall for open access resolution
- All search provider APIs

## ğŸ“ Support

- GitHub Issues: [Report bugs](https://github.com/research-system/research-agent/issues)
- Documentation: [Full docs](https://docs.research-system.io)
- Email: support@research-system.io

---

**Built with â¤ï¸ for PE-grade research automation**